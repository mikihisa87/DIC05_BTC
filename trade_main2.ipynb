{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.608219178082 {'criterion': 'gini', 'max_depth': 1}\n",
      "0.608219178082 {'criterion': 'gini', 'max_depth': 1}\n",
      "0.635616438356 {'criterion': 'gini', 'max_depth': 1, 'n_estimators': 3}\n",
      "0.624657534247 {'criterion': 'entropy', 'max_depth': 1, 'n_estimators': 11}\n",
      "0.668493150685 {'alpha': 0.0001, 'loss': 'huber', 'max_iter': 89, 'penalty': 'l2', 'shuffle': True}\n",
      "0.654794520548 {'alpha': 0.0001, 'loss': 'log', 'max_iter': 18, 'penalty': 'l1', 'shuffle': False}\n",
      "0.624657534247 {'C': 1, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.624657534247 {'C': 1, 'degree': 2, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "score_dt: 0.602739726027\n",
      "score_rf: 0.602739726027\n",
      "score_sgdc: 0.41095890411\n",
      "score_svm: 0.58904109589\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#os.chdir(\"../data\")\n",
    "dataset = pd.read_csv(\"Dataset.csv\")\n",
    "dataset.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "#dataset.set_index(\"date\")\n",
    "\n",
    "#add label\n",
    "price = dataset[\"price\"]\n",
    "pre_price = price.shift(-1)\n",
    "\n",
    "labels = []\n",
    "up = 1\n",
    "down = 0\n",
    "for i in range(len(dataset)):\n",
    "    if price[i] <= pre_price[i]:\n",
    "        labels.append(up)\n",
    "    else:\n",
    "        labels.append(down)\n",
    "\n",
    "dataset[\"label\"] = labels\n",
    "\n",
    "#パラメータ初期値\n",
    "dt_param1 = 'gini'\n",
    "dt_param2 = 1\n",
    "rf_param1 = 'gini'\n",
    "rf_param2 = 1\n",
    "rf_param3 = 12\n",
    "sgdc_param1 = 0.0001\n",
    "sgdc_param2 = 'log'\n",
    "sgdc_param3 = 43\n",
    "sgdc_param4 = 'elasticnet'\n",
    "sgdc_param5 = False\n",
    "svm_param1 = 1\n",
    "svm_param2 = 2\n",
    "svm_param3 = 0.001\n",
    "svm_param4 = 'poly'\n",
    "\n",
    "#Model定義\n",
    "clf_dt = tree.DecisionTreeClassifier(criterion=dt_param1, max_depth=dt_param2)\n",
    "clf_rf = ensemble.RandomForestClassifier(criterion=rf_param1, max_depth=rf_param2, n_estimators=rf_param2)\n",
    "clf_sgdc = SGDClassifier(alpha=sgdc_param1, loss=sgdc_param2, max_iter=sgdc_param3, penalty=sgdc_param4, shuffle=sgdc_param5)\n",
    "clf_svm = SVC(C=svm_param1, degree=svm_param2, gamma=svm_param3, kernel=svm_param4)\n",
    "\n",
    "#X, y定義\n",
    "X = dataset.drop(\"label\", axis=1)\n",
    "y = dataset[\"label\"]\n",
    "X = X.set_index('date')\n",
    "\n",
    "#正規化\n",
    "X_array = np.array(X)\n",
    "def zscore(X, axis=None):\n",
    "    xmean = X.mean(axis=axis, keepdims=True)\n",
    "    xstd = np.std(X, axis=axis, keepdims=True)\n",
    "    zscore = (X-xmean)/xstd\n",
    "    return zscore\n",
    "\n",
    "X_norm = zscore(X_array)\n",
    "\n",
    "#データ分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.2)#random_state=0\n",
    "\n",
    "#パラメータ最適化/Decision Tree\n",
    "def dtbestparam(X, y):\n",
    "    features = X\n",
    "    targets = y\n",
    "    #試行するパラメータを並べる\n",
    "    params = {\n",
    "        'max_depth' : list(range(1, 20)),\n",
    "        'criterion' : ['gini', 'entropy'],\n",
    "        }\n",
    "    grid_search = GridSearchCV(clf_dt, #分類器を渡す\n",
    "                                param_grid=params, #試行して欲しいパラメータを渡す\n",
    "                                cv=10, # 10-Fold CVで汎化性能を調べる\n",
    "                                )\n",
    "    grid_search.fit(features, targets)\n",
    "    print(grid_search.best_score_, grid_search.best_params_)\n",
    "    return grid_search.best_params_\n",
    "\n",
    "#パラメータ最適化/ensemble.RandomForestClassifier\n",
    "def rfbestparam(X, y):\n",
    "    features = X\n",
    "    targets = y\n",
    "    #試行するパラメータを並べる\n",
    "    params = {\n",
    "        'max_depth' : list(range(1, 20)),\n",
    "        'criterion' : ['gini', 'entropy'],\n",
    "        'n_estimators' : list(range(1, 20)),\n",
    "        }\n",
    "    grid_search = GridSearchCV(clf_rf, #分類器を渡す\n",
    "                                param_grid=params, #試行して欲しいパラメータを渡す\n",
    "                                cv=10, # 10-Fold CVで汎化性能を調べる\n",
    "                                )\n",
    "    grid_search.fit(features, targets)\n",
    "    print(grid_search.best_score_, grid_search.best_params_)\n",
    "    return grid_search.best_params_\n",
    "\n",
    "#パラメータ最適化/SGDClassifier\n",
    "def sgdcbestparam(X, y):\n",
    "    features = X\n",
    "    targets = y\n",
    "    #試行するパラメータを並べる\n",
    "    params = {\n",
    "        'loss' : ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_loss', 'huber', 'epsilon_insensitive',\n",
    "        'squared_epsilon_insensitive'],\n",
    "        'penalty' : ['None', 'l2', 'l1', 'elasticnet'],\n",
    "        'alpha' : list(np.arange(0.0001, 0.1, 10)),\n",
    "        'max_iter' : list(range(5, 100)),\n",
    "        'shuffle' : [False, True],\n",
    "        }\n",
    "    grid_search = GridSearchCV(clf_sgdc, #分類器を渡す\n",
    "                                param_grid=params, #試行して欲しいパラメータを渡す\n",
    "                                cv=10, # 10-Fold CVで汎化性能を調べる\n",
    "                                )\n",
    "    grid_search.fit(features, targets)\n",
    "    print(grid_search.best_score_, grid_search.best_params_)\n",
    "    return grid_search.best_params_\n",
    "\n",
    "#パラメータ最適化/SVM\n",
    "def svmbestparam(X, y):\n",
    "    features = X\n",
    "    targets = y\n",
    "    #試行するパラメータを並べる\n",
    "    params = {\n",
    "        'C' : [1, 10, 100, 1000],\n",
    "        'kernel' : ['poly', 'rbf', 'sigmoid'],\n",
    "        'degree' : [2, 3, 4],\n",
    "        'gamma' : [0.001, 0.0001],\n",
    "        }\n",
    "    grid_search = GridSearchCV(clf_svm, #分類器を渡す\n",
    "                                param_grid=params, #試行して欲しいパラメータを渡す\n",
    "                                cv=10, # 10-Fold CVで汎化性能を調べる\n",
    "                                )\n",
    "    grid_search.fit(features, targets)\n",
    "    print(grid_search.best_score_, grid_search.best_params_)\n",
    "    return grid_search.best_params_\n",
    "\n",
    "#Xとx_norm(正規化されたX)を各モデルに入れ、ベストパラメータを表示\n",
    "#dtbestparam(X, y)\n",
    "dtbestparam(X_norm, y)\n",
    "#取得したベストパラメータに代入、モデルのパラメータを更新(X_normの学習値を使用)\n",
    "dt_bestparam = dtbestparam(X_norm, y)\n",
    "dt_param1 = dt_bestparam['criterion']\n",
    "dt_param2 = dt_bestparam['max_depth']\n",
    "#Xとx_norm(正規化されたX)を各モデルに入れ、ベストパラメータを表示\n",
    "#rfbestparam(X, y)\n",
    "rfbestparam(X_norm, y)\n",
    "#取得したベストパラメータに代入、モデルのパラメータを更新(X_normの学習値を使用)\n",
    "rf_bestparam = rfbestparam(X_norm, y)\n",
    "rf_param1 = rf_bestparam['criterion']\n",
    "rf_param2 = rf_bestparam['max_depth']\n",
    "rf_param3 = rf_bestparam['n_estimators']\n",
    "#Xとx_norm(正規化されたX)を各モデルに入れ、ベストパラメータを表示\n",
    "#sgdcbestparam(X, y)\n",
    "sgdcbestparam(X_norm, y)\n",
    "#取得したベストパラメータに代入、モデルのパラメータを更新(X_normの学習値を使用)\n",
    "sgdc_bestparam = sgdcbestparam(X_norm, y)\n",
    "sgdc_param1 = sgdc_bestparam['alpha']\n",
    "sgdc_param2 = sgdc_bestparam['loss']\n",
    "sgdc_param3 = sgdc_bestparam['max_iter']\n",
    "sgdc_param4 = sgdc_bestparam['penalty']\n",
    "sgdc_param5 = sgdc_bestparam['shuffle']\n",
    "#Xとx_norm(正規化されたX)を各モデルに入れ、ベストパラメータを表示\n",
    "#svmbestparam(X, y)\n",
    "svmbestparam(X_norm, y)\n",
    "#取得したベストパラメータに代入、モデルのパラメータを更新(X_normの学習値を使用)\n",
    "svm_bestparam = svmbestparam(X_norm, y)\n",
    "svm_param1 = svm_bestparam['C']\n",
    "svm_param2 = svm_bestparam['degree']\n",
    "svm_param3 = svm_bestparam['gamma']\n",
    "svm_param4 = svm_bestparam['kernel']\n",
    "\n",
    "#Model再定義  \n",
    "clf_dt = tree.DecisionTreeClassifier(criterion=dt_param1, max_depth=dt_param2)\n",
    "clf_rf = ensemble.RandomForestClassifier(criterion=rf_param1, max_depth=rf_param2, n_estimators=rf_param2)\n",
    "clf_sgdc = SGDClassifier(alpha=sgdc_param1, loss=sgdc_param2, max_iter=sgdc_param3, penalty=sgdc_param4, shuffle=sgdc_param5)\n",
    "clf_svm = SVC(C=svm_param1, degree=svm_param2, gamma=svm_param3, kernel=svm_param4)\n",
    "\n",
    "#学習\n",
    "clf_dt.fit(X_train, y_train)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "clf_sgdc.fit(X_train, y_train)\n",
    "clf_svm.fit(X_train, y_train)\n",
    "\n",
    "#予測\n",
    "score_dt = clf_dt.score(X_test, y_test)\n",
    "score_rf = clf_rf.score(X_test, y_test)\n",
    "score_sgdc = clf_sgdc.score(X_test, y_test)\n",
    "score_svm = clf_svm.score(X_test, y_test)\n",
    "print(\"score_dt:\", score_dt)\n",
    "print(\"score_rf:\", score_rf)\n",
    "print(\"score_sgdc:\", score_sgdc)\n",
    "print(\"score_svm:\", score_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path = \"/Users/user/jupyter/DiveIntoCode/DIC05_BTC/EmotionScore.csv\"\n",
    "# emotion = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add label\n",
    "\"\"\"\n",
    "price = dataset[\"price\"]\n",
    "pre_price = price.shift(-1)\n",
    "\n",
    "labels = []\n",
    "up = 1\n",
    "down = 0\n",
    "for i in range(len(dataset)):\n",
    "    if price[i] <= pre_price[i]:\n",
    "        labels.append(up)\n",
    "    else:\n",
    "        labels.append(down)\n",
    "    \n",
    "dataset[\"label\"] = labels\n",
    "\n",
    "#Model定義\n",
    "clf_dt = tree.DecisionTreeClassifier()\n",
    "clf_rf = ensemble.RandomForestClassifier()\n",
    "clf_sgdc = SGDClassifier()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#正規化なし\n",
    "X = dataset.drop(columns=[\"label\"])\n",
    "y = dataset[\"label\"]\n",
    "\n",
    "#正規化あり\n",
    "X_array = np.array(X)\n",
    "def  zscore(X, axis=None):\n",
    "    xmean = X.mean(axis=axis, keepdims=True)\n",
    "    xstd = np.std(X, axis=axis, keepdims=True)\n",
    "    zscore = (X-xmean)/xstd\n",
    "    return zscore\n",
    "\n",
    "X_norm = zscore(X_array)\n",
    "\n",
    "def accuracy(clf, X, y, model): \n",
    "    cnt = 0\n",
    "    score_all = []\n",
    "    while cnt < 100:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)#random_state=0\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        score_all.append(score)\n",
    "        cnt +=1\n",
    "\n",
    "    score_all = np.array(score_all)\n",
    "    mscore = (score_all.mean())*100\n",
    "    print(\"{} Mean_Score :\".format(model), round(mscore, 2), \"%\")\n",
    "    return\n",
    "\n",
    "accuracy(clf_dt, X, y, \"DecisionTree\")\n",
    "accuracy(clf_dt, X_norm, y, \"DecisionTree with Norm\")\n",
    "accuracy(clf_rf, X, y, \"RamdomForest\")\n",
    "accuracy(clf_rf, X_norm, y, \"RamdomForest with Norm\")\n",
    "accuracy(clf_sgdc, X, y, \"SGDC\")\n",
    "accuracy(clf_sgdc, X_norm, y, \"SGDC with Norm\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
